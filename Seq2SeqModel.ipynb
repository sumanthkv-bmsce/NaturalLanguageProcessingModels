{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "courseraseq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbkAa9L9W96e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUIpBftgXQeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d0e6e347-8215-4dc1-cd25-c95dbbd3e9d0"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/hse-aml/natural-language-processing.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "AWS-tutorial.md  Docker-tutorial.md  README.md\t\t    week2\n",
            "common\t\t honor\t\t     setup_google_colab.py  week3\n",
            "docker\t\t project\t     week1\t\t    week4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY5ImwVNXQde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "7610ed2b-960b-4e37-8281-c85e9bf2eb91"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7XpvC6kYeBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "9784d4f2-732a-4a5d-b8a4-91723f1d0f3a"
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 96kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.4)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.28.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqdgipl7YyYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e519a86a-93f4-48f4-e65b-88ff3def02a9"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmMORvUfZIst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PGVIpyWZMre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_equations(allowed_operators, dataset_size, min_value, max_value):\n",
        "    \"\"\"Generates pairs of equations and solutions to them.\n",
        "    \n",
        "       Each equation has a form of two integers with an operator in between.\n",
        "       Each solution is an integer with the result of the operaion.\n",
        "    \n",
        "        allowed_operators: list of strings, allowed operators.\n",
        "        dataset_size: an integer, number of equations to be generated.\n",
        "        min_value: an integer, min value of each operand.\n",
        "        max_value: an integer, max value of each operand.\n",
        "\n",
        "        result: a list of tuples of strings (equation, solution).\n",
        "    \"\"\"\n",
        "    sample = []\n",
        "    for _ in range(dataset_size):\n",
        "        ######################################\n",
        "        ######### YOUR CODE HERE #############\n",
        "        ######################################\n",
        "        num1 = random.randint(min_value,max_value)\n",
        "        num2 = random.randint(min_value,max_value)\n",
        "        equa = num1+num2\n",
        "        st = str(num1)+'+'+str(num2)\n",
        "        sample.append((st,str(equa)))\n",
        "        equa = num1-num2\n",
        "        st = str(num1)+'-'+str(num2)\n",
        "        sample.append((st,str(equa)))\n",
        "\n",
        "\n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yMgiZdvbeFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_generate_equations():\n",
        "    allowed_operators = ['+', '-']\n",
        "    dataset_size = 10\n",
        "    for (input_, output_) in generate_equations(allowed_operators, dataset_size, 0, 100):\n",
        "        if not (type(input_) is str and type(output_) is str):\n",
        "            return \"Both parts should be strings.\"\n",
        "        if eval(input_) != int(output_):\n",
        "            return \"The (equation: {!r}, solution: {!r}) pair is incorrect.\".format(input_, output_)\n",
        "    return \"Tests passed.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojPbzkUObe4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2775d59e-0d42-4623-ec9d-b2b8bb28a53e"
      },
      "source": [
        "print(test_generate_equations())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_y6aIiPcTND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzHgtmzscgWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allowed_operators = ['+', '-']\n",
        "dataset_size = 100000\n",
        "data = generate_equations(allowed_operators, dataset_size, min_value=0, max_value=9999)\n",
        "\n",
        "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12A_L_tTch-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2id = {symbol:i for i, symbol in enumerate('#^$+-1234567890')}\n",
        "id2word = {i:symbol for symbol, i in word2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wv6cV6bdG_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "start_symbol = '^'\n",
        "end_symbol = '$'\n",
        "padding_symbol = '#'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXC4au0LdQ7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_to_ids(sentence, word2id, padded_len):\n",
        "    \"\"\" Converts a sequence of symbols to a padded sequence of their ids.\n",
        "    \n",
        "      sentence: a string, input/output sequence of symbols.\n",
        "      word2id: a dict, a mapping from original symbols to ids.\n",
        "      padded_len: an integer, a desirable length of the sequence.\n",
        "\n",
        "      result: a tuple of (a list of ids, an actual length of sentence).\n",
        "    \"\"\"\n",
        "    \n",
        "    sent_ids = []\n",
        "    for i in range(len(sentence)):\n",
        "      if i >= padded_len-1:\n",
        "        break\n",
        "      sent_ids.append(word2id[sentence[i]])\n",
        "    \n",
        "    sent_ids.append(word2id[\"$\"])\n",
        "    sent_len = len(sent_ids)\n",
        "    for i in range(padded_len-len(sent_ids)):\n",
        "      sent_ids.append(word2id[\"#\"])\n",
        "    \n",
        "    \n",
        "    return sent_ids, sent_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI15VB6PgIuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_sentence_to_ids():\n",
        "    sentences = [(\"123+123\", 7), (\"123+123\", 8), (\"123+123\", 10)]\n",
        "    expected_output = [([5, 6, 7, 3, 5, 6, 2], 7), \n",
        "                       ([5, 6, 7, 3, 5, 6, 7, 2], 8), \n",
        "                       ([5, 6, 7, 3, 5, 6, 7, 2, 0, 0], 8)] \n",
        "    for (sentence, padded_len), (sentence_ids, expected_length) in zip(sentences, expected_output):\n",
        "        output, length = sentence_to_ids(sentence, word2id, padded_len)\n",
        "        if output != sentence_ids:\n",
        "            return(\"Convertion of '{}' for padded_len={} to {} is incorrect.\".format(\n",
        "                sentence, padded_len, output))\n",
        "        if length != expected_length:\n",
        "            return(\"Convertion of '{}' for padded_len={} has incorrect actual length {}.\".format(\n",
        "                sentence, padded_len, length))\n",
        "    return(\"Tests passed.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRqJV-2RgK7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a899b16d-e475-4c3d-c30e-3bea57f8fa77"
      },
      "source": [
        "\n",
        "print(test_sentence_to_ids())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tests passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiJJU_akgNnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ids_to_sentence(ids, id2word):\n",
        "    \"\"\" Converts a sequence of ids to a sequence of symbols.\n",
        "    \n",
        "          ids: a list, indices for the padded sequence.\n",
        "          id2word:  a dict, a mapping from ids to original symbols.\n",
        "\n",
        "          result: a list of symbols.\n",
        "    \"\"\"\n",
        " \n",
        "    return [id2word[i] for i in ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxE-BkugkD_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def batch_to_ids(sentences, word2id, max_len):\n",
        "    \"\"\"Prepares batches of indices. \n",
        "    \n",
        "       Sequences are padded to match the longest sequence in the batch,\n",
        "       if it's longer than max_len, then max_len is used instead.\n",
        "\n",
        "        sentences: a list of strings, original sequences.\n",
        "        word2id: a dict, a mapping from original symbols to ids.\n",
        "        max_len: an integer, max len of sequences allowed.\n",
        "\n",
        "        result: a list of lists of ids, a list of actual lengths.\n",
        "    \"\"\"\n",
        "    \n",
        "    max_len_in_batch = min(max(len(s) for s in sentences) + 1, max_len)\n",
        "    batch_ids, batch_ids_len = [], []\n",
        "    for sentence in sentences:\n",
        "        ids, ids_len = sentence_to_ids(sentence, word2id, max_len_in_batch)\n",
        "        batch_ids.append(ids)\n",
        "        batch_ids_len.append(ids_len)\n",
        "    return batch_ids, batch_ids_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUQO9y1kKig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(samples, batch_size=64):\n",
        "    X, Y = [], []\n",
        "    for i, (x, y) in enumerate(samples, 1):\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "        if i % batch_size == 0:\n",
        "            yield X, Y\n",
        "            X, Y = [], []\n",
        "    if X and Y:\n",
        "        yield X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfpqe78HkX2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f580d763-5105-40f5-effa-845cdc28ee78"
      },
      "source": [
        "sentences = train_set[0]\n",
        "ids, sent_lens = batch_to_ids(sentences, word2id, max_len=10)\n",
        "print('Input:', sentences)\n",
        "print('Ids: {}\\nSentences lengths: {}'.format(ids, sent_lens))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ('855+9988', '10843')\n",
            "Ids: [[12, 9, 9, 3, 13, 13, 12, 12, 2], [5, 14, 12, 8, 7, 2, 0, 0, 0]]\n",
            "Sentences lengths: [9, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6Wr1PtkdGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqModel(object):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4uT6golLfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def declare_placeholders(self):\n",
        "    \"\"\"Specifies placeholders for the model.\"\"\"\n",
        "    \n",
        "    # Placeholders for input and its actual lengths.\n",
        "    self.input_batch = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input_batch')\n",
        "    self.input_batch_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='input_batch_lengths')\n",
        "    \n",
        "    # Placeholders for groundtruth and its actual lengths.\n",
        "    self.ground_truth = tf.placeholder(shape=(None,None),dtype=tf.int32,name=\"ground_truth\")\n",
        "    self.ground_truth_lengths = tf.placeholder(shape=(None,),dtype=tf.int32,name=\"ground_truth_lengths\" )\n",
        "        \n",
        "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
        "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32,shape=[],name=\"learning_rate_ph\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlBxu-vjl8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__declare_placeholders = classmethod(declare_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnoztDMMl_jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embeddings(self, vocab_size, embeddings_size):\n",
        "    \"\"\"Specifies embeddings layer and embeds an input batch.\"\"\"\n",
        "     \n",
        "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
        "    self.embeddings = tf.Variable(random_initializer,dtype=tf.float32,name=\"embeddings\") \n",
        "    \n",
        "    # Perform embeddings lookup for self.input_batch. \n",
        "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings,self.input_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImpK-QeOpOgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__create_embeddings = classmethod(create_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtOrAxR7pS6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(self, hidden_size):\n",
        "    \"\"\"Specifies encoder architecture and computes its output.\"\"\"\n",
        "    \n",
        "    # Create GRUCell with dropout.\n",
        "    encoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(num_units=hidden_size,dtype=tf.float32),input_keep_prob=self.dropout_ph)\n",
        "    \n",
        "    # Create RNN with the predefined cell.\n",
        "    _, self.final_encoder_state = tf.nn.dynamic_rnn(encoder_cell,self.input_batch_embedded,sequence_length=self.input_batch_lengths,dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaBBYUZYtsQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__build_encoder = classmethod(build_encoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FkXPX0st9mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_decoder(self, hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id):\n",
        "    \"\"\"Specifies decoder architecture and computes the output.\n",
        "    \n",
        "        Uses different helpers:\n",
        "          - for train: feeding ground truth\n",
        "          - for inference: feeding generated output\n",
        "\n",
        "        As a result, self.train_outputs and self.infer_outputs are created. \n",
        "        Each of them contains two fields:\n",
        "          rnn_output (predicted logits)\n",
        "          sample_id (predictions).\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Use start symbols as the decoder inputs at the first time step.\n",
        "    batch_size = tf.shape(self.input_batch)[0]\n",
        "    start_tokens = tf.fill([batch_size], start_symbol_id)\n",
        "    ground_truth_as_input = tf.concat([tf.expand_dims(start_tokens, 1), self.ground_truth], 1)\n",
        "    \n",
        "    # Use the embedding layer defined before to lookup embedings for ground_truth_as_input. \n",
        "    self.ground_truth_embedded =tf.nn.embedding_lookup(self.embeddings,ground_truth_as_input)\n",
        "     \n",
        "    # Create TrainingHelper for the train stage.\n",
        "    train_helper = tf.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded, \n",
        "                                                     self.ground_truth_lengths)\n",
        "    \n",
        "    # Create GreedyEmbeddingHelper for the inference stage.\n",
        "    # You should provide the embedding layer, start_tokens and index of the end symbol.\n",
        "    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embeddings,start_tokens=start_tokens,end_token=end_symbol_id)\n",
        "    \n",
        "  \n",
        "    def decode(helper, scope, reuse=None):\n",
        "        \"\"\"Creates decoder and return the results of the decoding with a given helper.\"\"\"\n",
        "        \n",
        "        with tf.variable_scope(scope, reuse=reuse):\n",
        "            # Create GRUCell with dropout. Do not forget to set the reuse flag properly.\n",
        "            decoder_cell = tf.contrib.rnn.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size,reuse=reuse),dtype=tf.float32,input_keep_prob=self.dropout_ph)\n",
        "            \n",
        "            # Create a projection wrapper.\n",
        "            decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, vocab_size, reuse=reuse)\n",
        "            \n",
        "            # Create BasicDecoder, pass the defined cell, a helper, and initial state.\n",
        "            # The initial state should be equal to the final state of the encoder!\n",
        "            decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,helper=helper,initial_state=self.final_encoder_state)\n",
        "            \n",
        "            # The first returning argument of dynamic_decode contains two fields:\n",
        "            #   rnn_output (predicted logits)\n",
        "            #   sample_id (predictions)\n",
        "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_iter, \n",
        "                                                              output_time_major=False, impute_finished=True)\n",
        "\n",
        "            return outputs\n",
        "        \n",
        "    self.train_outputs = decode(train_helper, 'decode')\n",
        "    self.infer_outputs = decode(infer_helper, 'decode', reuse=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5oH24ef4T1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__build_decoder = classmethod(build_decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPgvPzZe4aXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(self):\n",
        "    \"\"\"Computes sequence loss (masked cross-entopy loss with logits).\"\"\"\n",
        "    \n",
        "    weights = tf.cast(tf.sequence_mask(self.ground_truth_lengths), dtype=tf.float32)\n",
        "    \n",
        "    self.loss = tf.contrib.seq2seq.sequence_loss(self.train_outputs.rnn_output,self.ground_truth,weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iJFIOg1529N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__compute_loss = classmethod(compute_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpA5MC6E6FkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def perform_optimization(self):\n",
        "    \"\"\"Specifies train_op that optimizes self.loss.\"\"\"\n",
        "    \n",
        "    self.train_op = tf.contrib.layers.optimize_loss(self.loss,global_step=tf.train.get_global_step(),\n",
        "                                                    learning_rate=self.learning_rate_ph,clip_gradients=1.0,optimizer=\"Adam\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKdnCR4K7LnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__perform_optimization = classmethod(perform_optimization)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbvB1FsD7N5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_model(self, vocab_size, embeddings_size, hidden_size, \n",
        "               max_iter, start_symbol_id, end_symbol_id, padding_symbol_id):\n",
        "    \n",
        "    self.__declare_placeholders()\n",
        "    self.__create_embeddings(vocab_size, embeddings_size)\n",
        "    self.__build_encoder(hidden_size)\n",
        "    self.__build_decoder(hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id)\n",
        "    \n",
        "    # Compute loss and back-propagate.\n",
        "    self.__compute_loss()\n",
        "    self.__perform_optimization()\n",
        "    \n",
        "    # Get predictions for evaluation.\n",
        "    self.train_predictions = self.train_outputs.sample_id\n",
        "    self.infer_predictions = self.infer_outputs.sample_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD2tEf_J7PdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.__init__ = classmethod(init_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn9hHELz7RPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_on_batch(self, session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability):\n",
        "    feed_dict = {\n",
        "            self.input_batch: X,\n",
        "            self.input_batch_lengths: X_seq_len,\n",
        "            self.ground_truth: Y,\n",
        "            self.ground_truth_lengths: Y_seq_len,\n",
        "            self.learning_rate_ph: learning_rate,\n",
        "            self.dropout_ph: dropout_keep_probability\n",
        "        }\n",
        "    pred, loss, _ = session.run([\n",
        "            self.train_predictions,\n",
        "            self.loss,\n",
        "            self.train_op], feed_dict=feed_dict)\n",
        "    return pred, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2h-NMxw7blq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.train_on_batch = classmethod(train_on_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47kghMab7f9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_for_batch(self, session, X, X_seq_len):\n",
        "    feed_dict = {\n",
        "        self.input_batch:X,\n",
        "        self.input_batch_lengths:X_seq_len\n",
        "    }\n",
        "    pred = session.run([\n",
        "            self.infer_predictions\n",
        "        ], feed_dict=feed_dict)[0]\n",
        "    return pred\n",
        "\n",
        "def predict_for_batch_with_loss(self, session, X, X_seq_len, Y, Y_seq_len):\n",
        "    feed_dict = {\n",
        "        self.input_batch:X,\n",
        "        self.input_batch_lengths:X_seq_len,\n",
        "        self.ground_truth: Y,\n",
        "        self.ground_truth_lengths:Y_seq_len\n",
        "    }\n",
        "    pred, loss = session.run([\n",
        "            self.infer_predictions,\n",
        "            self.loss,\n",
        "        ], feed_dict=feed_dict)\n",
        "    return pred, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xQC46X98WjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Seq2SeqModel.predict_for_batch = classmethod(predict_for_batch)\n",
        "Seq2SeqModel.predict_for_batch_with_loss = classmethod(predict_for_batch_with_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDrXKQyV8ZzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3ea2f57f-b70d-4855-e645-ec725a7bb7ea"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "model = Seq2SeqModel(vocab_size=len(word2id),embeddings_size=20,hidden_size=512,max_iter=7,start_symbol_id=word2id[start_symbol],\n",
        "                     end_symbol_id=word2id[end_symbol],padding_symbol_id=word2id[padding_symbol])\n",
        "\n",
        "batch_size = 128\n",
        "n_epochs = 10\n",
        "learning_rate = 0.001\n",
        "dropout_keep_probability = 0.5\n",
        "max_len = 20\n",
        "\n",
        "n_step = int(len(train_set) / batch_size)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d60c07518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d60c07518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d60c07518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d60c07518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef24a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef24a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef24a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef24a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f5860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f5860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f5860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f5860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method OutputProjectionWrapper.call of <tensorflow.contrib.rnn.python.ops.core_rnn_cell.OutputProjectionWrapper object at 0x7f9d60ef26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f53c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f53c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f53c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f9d609f53c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiZCOSN-8qIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad18d1e9-8ce3-4695-b5f9-df4dbd6b00ba"
      },
      "source": [
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "            \n",
        "invalid_number_prediction_counts = []\n",
        "all_model_predictions = []\n",
        "all_ground_truth = []\n",
        "\n",
        "print('Start training... \\n')\n",
        "for epoch in range(n_epochs):  \n",
        "    random.shuffle(train_set)\n",
        "    random.shuffle(test_set)\n",
        "    \n",
        "    print('Train: epoch', epoch + 1)\n",
        "    for n_iter, (X_batch, Y_batch) in enumerate(generate_batches(train_set, batch_size=batch_size)):\n",
        "        ######################################\n",
        "        ######### YOUR CODE HERE #############\n",
        "        ######################################\n",
        "        # prepare the data (X_batch and Y_batch) for training\n",
        "        # using function batch_to_ids\n",
        "\n",
        "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
        "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
        "        predictions, loss = model.train_on_batch(session, \n",
        "                                                X, \n",
        "                                                X_seq_len, \n",
        "                                                Y, \n",
        "                                                Y_seq_len, \n",
        "                                                learning_rate, \n",
        "                                                dropout_keep_probability)\n",
        "        \n",
        "        if n_iter % 200 == 0:\n",
        "            print(\"Epoch: [%d/%d], step: [%d/%d], loss: %f\" % (epoch + 1, n_epochs, n_iter + 1, n_step, loss))\n",
        "                \n",
        "    X_sent, Y_sent = next(generate_batches(test_set, batch_size=batch_size))\n",
        "    ######################################\n",
        "    ######### YOUR CODE HERE #############\n",
        "    ######################################\n",
        "    # prepare test data (X_sent and Y_sent) for predicting \n",
        "    # quality and computing value of the loss function\n",
        "    # using function batch_to_ids\n",
        "    X, X_seq_len = batch_to_ids(X_sent, word2id, max_len)\n",
        "    Y, Y_seq_len = batch_to_ids(Y_sent, word2id, max_len)\n",
        "    predictions, loss = model.predict_for_batch_with_loss(session, \n",
        "                                                X, \n",
        "                                                X_seq_len, \n",
        "                                                Y, \n",
        "                                                Y_seq_len) \n",
        "    \n",
        "    print('Test: epoch', epoch + 1, 'loss:', loss,)\n",
        "    for x, y, p  in list(zip(X, Y, predictions))[:3]:\n",
        "        print('X:',''.join(ids_to_sentence(x, id2word)))\n",
        "        print('Y:',''.join(ids_to_sentence(y, id2word)))\n",
        "        print('O:',''.join(ids_to_sentence(p, id2word)))\n",
        "        print('')\n",
        "\n",
        "    model_predictions = []\n",
        "    ground_truth = []\n",
        "    invalid_number_prediction_count = 0\n",
        "    # For the whole test set calculate ground-truth values (as integer numbers)\n",
        "    # and prediction values (also as integers) to calculate metrics.\n",
        "    # If generated by model number is not correct (e.g. '1-1'), \n",
        "    # increase invalid_number_prediction_count and don't append this and corresponding\n",
        "    # ground-truth value to the arrays.\n",
        "    for X_batch, Y_batch in generate_batches(test_set, batch_size=batch_size):\n",
        "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
        "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
        "        predictions, loss = model.predict_for_batch_with_loss(session, X, X_seq_len, Y, Y_seq_len)\n",
        "    \n",
        "    all_model_predictions.append(model_predictions)\n",
        "    all_ground_truth.append(ground_truth)\n",
        "    invalid_number_prediction_counts.append(invalid_number_prediction_count)\n",
        "            \n",
        "print('\\n...training finished.')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training... \n",
            "\n",
            "Train: epoch 1\n",
            "Epoch: [1/10], step: [1/1250], loss: 2.705241\n",
            "Epoch: [1/10], step: [201/1250], loss: 1.802342\n",
            "Epoch: [1/10], step: [401/1250], loss: 1.663049\n",
            "Epoch: [1/10], step: [601/1250], loss: 1.631186\n",
            "Epoch: [1/10], step: [801/1250], loss: 1.553585\n",
            "Epoch: [1/10], step: [1001/1250], loss: 1.521577\n",
            "Epoch: [1/10], step: [1201/1250], loss: 1.452955\n",
            "Test: epoch 1 loss: 1.3925002\n",
            "X: 2626+4270$\n",
            "Y: 6896$#\n",
            "O: 6521$#\n",
            "\n",
            "X: 6486+5330$\n",
            "Y: 11816$\n",
            "O: 12224$\n",
            "\n",
            "X: 9699-1318$\n",
            "Y: 8381$#\n",
            "O: 8231$#\n",
            "\n",
            "Train: epoch 2\n",
            "Epoch: [2/10], step: [1/1250], loss: 1.496710\n",
            "Epoch: [2/10], step: [201/1250], loss: 1.431549\n",
            "Epoch: [2/10], step: [401/1250], loss: 1.430471\n",
            "Epoch: [2/10], step: [601/1250], loss: 1.419047\n",
            "Epoch: [2/10], step: [801/1250], loss: 1.394574\n",
            "Epoch: [2/10], step: [1001/1250], loss: 1.364852\n",
            "Epoch: [2/10], step: [1201/1250], loss: 1.353233\n",
            "Test: epoch 2 loss: 1.3016651\n",
            "X: 6373+5079$\n",
            "Y: 11452$\n",
            "O: 11271$\n",
            "\n",
            "X: 5261+7583$\n",
            "Y: 12844$\n",
            "O: 12270$\n",
            "\n",
            "X: 4630+9111$\n",
            "Y: 13741$\n",
            "O: 13400$\n",
            "\n",
            "Train: epoch 3\n",
            "Epoch: [3/10], step: [1/1250], loss: 1.391580\n",
            "Epoch: [3/10], step: [201/1250], loss: 1.382258\n",
            "Epoch: [3/10], step: [401/1250], loss: 1.326612\n",
            "Epoch: [3/10], step: [601/1250], loss: 1.343349\n",
            "Epoch: [3/10], step: [801/1250], loss: 1.337238\n",
            "Epoch: [3/10], step: [1001/1250], loss: 1.286217\n",
            "Epoch: [3/10], step: [1201/1250], loss: 1.287037\n",
            "Test: epoch 3 loss: 1.2430062\n",
            "X: 1240+7881$\n",
            "Y: 9121$#\n",
            "O: 9193$#\n",
            "\n",
            "X: 9033-5429$\n",
            "Y: 3604$#\n",
            "O: 3388$#\n",
            "\n",
            "X: 3353+2075$\n",
            "Y: 5428$#\n",
            "O: 5758$#\n",
            "\n",
            "Train: epoch 4\n",
            "Epoch: [4/10], step: [1/1250], loss: 1.321249\n",
            "Epoch: [4/10], step: [201/1250], loss: 1.283087\n",
            "Epoch: [4/10], step: [401/1250], loss: 1.274870\n",
            "Epoch: [4/10], step: [601/1250], loss: 1.209471\n",
            "Epoch: [4/10], step: [801/1250], loss: 1.192103\n",
            "Epoch: [4/10], step: [1001/1250], loss: 1.173531\n",
            "Epoch: [4/10], step: [1201/1250], loss: 1.135580\n",
            "Test: epoch 4 loss: 1.0466967\n",
            "X: 6932+589$#\n",
            "Y: 7521$#\n",
            "O: 7619$#\n",
            "\n",
            "X: 1836-5709$\n",
            "Y: -3873$\n",
            "O: -3999$\n",
            "\n",
            "X: 6980-8366$\n",
            "Y: -1386$\n",
            "O: -1444$\n",
            "\n",
            "Train: epoch 5\n",
            "Epoch: [5/10], step: [1/1250], loss: 1.125432\n",
            "Epoch: [5/10], step: [201/1250], loss: 1.082103\n",
            "Epoch: [5/10], step: [401/1250], loss: 1.060465\n",
            "Epoch: [5/10], step: [601/1250], loss: 1.042980\n",
            "Epoch: [5/10], step: [801/1250], loss: 0.991886\n",
            "Epoch: [5/10], step: [1001/1250], loss: 1.074792\n",
            "Epoch: [5/10], step: [1201/1250], loss: 1.003951\n",
            "Test: epoch 5 loss: 0.92846495\n",
            "X: 70-7874$##\n",
            "Y: -7804$\n",
            "O: -7737$\n",
            "\n",
            "X: 9914-6616$\n",
            "Y: 3298$#\n",
            "O: 3297$#\n",
            "\n",
            "X: 3827+834$#\n",
            "Y: 4661$#\n",
            "O: 4667$#\n",
            "\n",
            "Train: epoch 6\n",
            "Epoch: [6/10], step: [1/1250], loss: 0.960063\n",
            "Epoch: [6/10], step: [201/1250], loss: 0.994832\n",
            "Epoch: [6/10], step: [401/1250], loss: 0.979438\n",
            "Epoch: [6/10], step: [601/1250], loss: 0.964959\n",
            "Epoch: [6/10], step: [801/1250], loss: 0.955709\n",
            "Epoch: [6/10], step: [1001/1250], loss: 0.919583\n",
            "Epoch: [6/10], step: [1201/1250], loss: 0.918530\n",
            "Test: epoch 6 loss: 0.8516747\n",
            "X: 9793-2958$\n",
            "Y: 6835$#\n",
            "O: 6899$#\n",
            "\n",
            "X: 2427+2816$\n",
            "Y: 5243$#\n",
            "O: 5229$#\n",
            "\n",
            "X: 2272+9053$\n",
            "Y: 11325$\n",
            "O: 11333$\n",
            "\n",
            "Train: epoch 7\n",
            "Epoch: [7/10], step: [1/1250], loss: 0.951020\n",
            "Epoch: [7/10], step: [201/1250], loss: 0.925654\n",
            "Epoch: [7/10], step: [401/1250], loss: 0.942029\n",
            "Epoch: [7/10], step: [601/1250], loss: 0.873981\n",
            "Epoch: [7/10], step: [801/1250], loss: 0.899276\n",
            "Epoch: [7/10], step: [1001/1250], loss: 0.889592\n",
            "Epoch: [7/10], step: [1201/1250], loss: 0.879879\n",
            "Test: epoch 7 loss: 0.8124163\n",
            "X: 1844-5843$\n",
            "Y: -3999$\n",
            "O: -3990$\n",
            "\n",
            "X: 5037+5414$\n",
            "Y: 10451$\n",
            "O: 10468$\n",
            "\n",
            "X: 5236-5086$\n",
            "Y: 150$##\n",
            "O: 119$##\n",
            "\n",
            "Train: epoch 8\n",
            "Epoch: [8/10], step: [1/1250], loss: 0.856187\n",
            "Epoch: [8/10], step: [201/1250], loss: 0.843299\n",
            "Epoch: [8/10], step: [401/1250], loss: 0.864724\n",
            "Epoch: [8/10], step: [601/1250], loss: 0.863434\n",
            "Epoch: [8/10], step: [801/1250], loss: 0.826822\n",
            "Epoch: [8/10], step: [1001/1250], loss: 0.858745\n",
            "Epoch: [8/10], step: [1201/1250], loss: 0.814861\n",
            "Test: epoch 8 loss: 0.8082278\n",
            "X: 9209-8953$\n",
            "Y: 256$##\n",
            "O: 299$##\n",
            "\n",
            "X: 3953-258$#\n",
            "Y: 3695$#\n",
            "O: 3699$#\n",
            "\n",
            "X: 9016-8895$\n",
            "Y: 121$##\n",
            "O: 155$##\n",
            "\n",
            "Train: epoch 9\n",
            "Epoch: [9/10], step: [1/1250], loss: 0.807975\n",
            "Epoch: [9/10], step: [201/1250], loss: 0.827380\n",
            "Epoch: [9/10], step: [401/1250], loss: 0.814503\n",
            "Epoch: [9/10], step: [601/1250], loss: 0.820770\n",
            "Epoch: [9/10], step: [801/1250], loss: 0.826308\n",
            "Epoch: [9/10], step: [1001/1250], loss: 0.827884\n",
            "Epoch: [9/10], step: [1201/1250], loss: 0.808638\n",
            "Test: epoch 9 loss: 0.77091914\n",
            "X: 4811+7648$\n",
            "Y: 12459$\n",
            "O: 12471$\n",
            "\n",
            "X: 771-9601$#\n",
            "Y: -8830$\n",
            "O: -8855$\n",
            "\n",
            "X: 6879+1572$\n",
            "Y: 8451$#\n",
            "O: 8490$#\n",
            "\n",
            "Train: epoch 10\n",
            "Epoch: [10/10], step: [1/1250], loss: 0.784003\n",
            "Epoch: [10/10], step: [201/1250], loss: 0.775744\n",
            "Epoch: [10/10], step: [401/1250], loss: 0.787626\n",
            "Epoch: [10/10], step: [601/1250], loss: 0.816603\n",
            "Epoch: [10/10], step: [801/1250], loss: 0.747038\n",
            "Epoch: [10/10], step: [1001/1250], loss: 0.782333\n",
            "Epoch: [10/10], step: [1201/1250], loss: 0.759115\n",
            "Test: epoch 10 loss: 0.7408289\n",
            "X: 5160+3800$\n",
            "Y: 8960$#\n",
            "O: 9961$#\n",
            "\n",
            "X: 282+4552$#\n",
            "Y: 4834$#\n",
            "O: 4865$#\n",
            "\n",
            "X: 7743-190$#\n",
            "Y: 7553$#\n",
            "O: 7565$#\n",
            "\n",
            "\n",
            "...training finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nDnt31QBhZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}